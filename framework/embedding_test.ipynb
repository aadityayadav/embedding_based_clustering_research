{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustbench \n",
    "import os.path, genieclust, sklearn.cluster # we will need these later\n",
    "import matplotlib.pyplot as plt, numpy as np, pandas as pd\n",
    "import csv\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, MeanShift, SpectralClustering, AffinityPropagation, OPTICS, Birch, MiniBatchKMeans, SpectralCoclustering\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import hdbscan\n",
    "from kmodes.kmodes import KModes\n",
    "from fcmeans import FCM\n",
    "from minisom import MiniSom\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(X):\n",
    "    \"\"\"\n",
    "    Generate a dictionary of embeddings from a multidimensional NumPy array of numbers.\n",
    "\n",
    "    This function applies both traditional numerical embeddings and text-based embedding\n",
    "    techniques (by converting numeric rows to strings) to produce a variety of representations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : numpy.ndarray\n",
    "        A 2D array of shape (n_samples, n_features) containing numeric data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        A dictionary where the key \"Base\" corresponds to the original data and additional\n",
    "        keys correspond to various embedded representations.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    embeddings = {\"Base\": X}\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 1. Traditional Numerical Embeddings\n",
    "    # ------------------------------------------------\n",
    "    try:\n",
    "        from sklearn.decomposition import (\n",
    "            PCA, KernelPCA, TruncatedSVD, FastICA, FactorAnalysis\n",
    "        )\n",
    "        from sklearn.manifold import (\n",
    "            TSNE, MDS, Isomap, LocallyLinearEmbedding, SpectralEmbedding\n",
    "        )\n",
    "        from sklearn.random_projection import GaussianRandomProjection\n",
    "        \n",
    "        # PCA\n",
    "        # Common default: n_components=2 for visualization; whiten=False (unless needed)\n",
    "        pca_model = PCA(n_components=2, whiten=False, random_state=42)\n",
    "        embeddings[\"PCA\"] = pca_model.fit_transform(X)\n",
    "        print(\"PCA embedding done.\")\n",
    "\n",
    "        # t-SNE\n",
    "        # Common defaults: n_components=2, perplexity=30, learning_rate='auto', n_iter=1000+\n",
    "        # Note: t-SNE can be slow on large datasets. \n",
    "        tsne_model = TSNE(\n",
    "            n_components=2,\n",
    "            perplexity=30,\n",
    "            learning_rate='auto',\n",
    "            max_iter=1000,\n",
    "            random_state=42,\n",
    "            init='pca'  # often helps with convergence\n",
    "        )\n",
    "        embeddings[\"t-SNE\"] = tsne_model.fit_transform(X)\n",
    "        print(\"t-SNE embedding done.\")\n",
    "\n",
    "        # UMAP (requires umap-learn)\n",
    "        # Common defaults: n_neighbors=15, min_dist=0.1, metric='euclidean'\n",
    "        # NOTE: This can be slow for large data. Increase n_epochs or do PCA first if needed.\n",
    "        try:\n",
    "            import umap\n",
    "            umap_model = umap.UMAP(\n",
    "                n_components=2,\n",
    "                n_neighbors=15,\n",
    "                min_dist=0.1,\n",
    "                metric='euclidean',\n",
    "                random_state=42\n",
    "            )\n",
    "            embeddings[\"UMAP\"] = umap_model.fit_transform(X)\n",
    "            print(\"UMAP embedding done.\")\n",
    "        except Exception as e:\n",
    "            print(\"UMAP embedding failed:\", e)\n",
    "\n",
    "        # MDS\n",
    "        # Default: n_components=2, metric=True (classical MDS), can be slow for large data\n",
    "        mds_model = MDS(n_components=2, metric=True, random_state=42, n_init=4, max_iter=300)\n",
    "        embeddings[\"MDS\"] = mds_model.fit_transform(X)\n",
    "        print(\"MDS embedding done.\")\n",
    "\n",
    "        # Isomap\n",
    "        # Default: n_neighbors=5, n_components=2\n",
    "        isomap_model = Isomap(n_components=2, n_neighbors=5)\n",
    "        embeddings[\"Isomap\"] = isomap_model.fit_transform(X)\n",
    "        print(\"Isomap embedding done.\")\n",
    "\n",
    "        # Locally Linear Embedding (LLE)\n",
    "        # Default: n_neighbors=10, n_components=2\n",
    "        lle_model = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)\n",
    "        embeddings[\"LLE\"] = lle_model.fit_transform(X)\n",
    "        print(\"LLE embedding done.\")\n",
    "\n",
    "        # Spectral Embedding\n",
    "        # Default: n_components=2, affinity='nearest_neighbors', n_neighbors=5\n",
    "        spectral_model = SpectralEmbedding(\n",
    "            n_components=2,\n",
    "            n_neighbors=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        embeddings[\"Spectral\"] = spectral_model.fit_transform(X)\n",
    "        print(\"Spectral embedding done.\")\n",
    "\n",
    "        # Kernel PCA with RBF kernel\n",
    "        # Common defaults: n_components=2, kernel='rbf', gamma=None (auto)\n",
    "        kpca_model = KernelPCA(\n",
    "            n_components=2,\n",
    "            kernel='rbf',\n",
    "            gamma=None,\n",
    "            random_state=42\n",
    "        )\n",
    "        embeddings[\"KernelPCA\"] = kpca_model.fit_transform(X)\n",
    "        print(\"Kernel PCA embedding done.\")\n",
    "\n",
    "        # Autoencoder embedding (using TensorFlow/Keras)\n",
    "        # Basic architecture: input->(64)->(32)->(2)->(32)->(64)->output\n",
    "        # Epochs, batch_size can be tuned for better performance\n",
    "        try:\n",
    "            import tensorflow as tf\n",
    "            from tensorflow.keras.layers import Input, Dense\n",
    "            from tensorflow.keras.models import Model\n",
    "\n",
    "            input_dim = X.shape[1]\n",
    "            encoding_dim = 2  # target dimension\n",
    "            input_layer = Input(shape=(input_dim,))\n",
    "            encoded = Dense(64, activation='relu')(input_layer)\n",
    "            encoded = Dense(32, activation='relu')(encoded)\n",
    "            bottleneck = Dense(encoding_dim, activation='linear')(encoded)\n",
    "            decoded = Dense(32, activation='relu')(bottleneck)\n",
    "            decoded = Dense(64, activation='relu')(decoded)\n",
    "            output_layer = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "            autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "            autoencoder.compile(optimizer='adam', loss='mse')\n",
    "            # Train briefly (increase epochs for better results on real data)\n",
    "            autoencoder.fit(X, X, epochs=50, batch_size=32, verbose=0)\n",
    "            encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
    "            embeddings[\"Autoencoder\"] = encoder.predict(X)\n",
    "            print(\"Autoencoder embedding done.\")\n",
    "        except Exception as e:\n",
    "            print(\"Autoencoder embedding failed:\", e)\n",
    "\n",
    "        # Random Projection\n",
    "        # Common default: n_components=2, use GaussianRandomProjection\n",
    "        rp = GaussianRandomProjection(n_components=2, eps=0.1, random_state=42)\n",
    "        embeddings[\"RandomProjection\"] = rp.fit_transform(X)\n",
    "        print(\"Random Projection embedding done.\")\n",
    "\n",
    "        # Truncated SVD\n",
    "        # Common default: n_components=2, good for sparse data (like TF-IDF)\n",
    "        svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "        embeddings[\"TruncatedSVD\"] = svd.fit_transform(X)\n",
    "        print(\"Truncated SVD embedding done.\")\n",
    "\n",
    "        # FastICA\n",
    "        # Common defaults: n_components=2, whiten=True, max_iter=200\n",
    "        ica = FastICA(n_components=2, whiten=True, max_iter=200, random_state=42)\n",
    "        embeddings[\"FastICA\"] = ica.fit_transform(X)\n",
    "        print(\"FastICA embedding done.\")\n",
    "\n",
    "        # Factor Analysis\n",
    "        # Default: n_components=2\n",
    "        fa = FactorAnalysis(n_components=2, random_state=42)\n",
    "        embeddings[\"FactorAnalysis\"] = fa.fit_transform(X)\n",
    "        print(\"Factor Analysis embedding done.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in numerical embeddings:\", e)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 2. Text-Based Embeddings on Numeric Data\n",
    "    #    (Convert each row to a string, then treat it as text)\n",
    "    # ------------------------------------------------\n",
    "    try:\n",
    "        # Convert each row (sample) to a space-separated string, e.g., \"0.12 0.57 0.99 ...\"\n",
    "        X_as_str = [\" \".join(map(str, row)) for row in X]\n",
    "        print(\"Converted numeric data to strings.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error converting numeric data to strings:\", e)\n",
    "        X_as_str = []\n",
    "\n",
    "    # TF-IDF Vectorizer\n",
    "    # Common defaults: max_features=500 (can raise if large vocabulary)\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "        X_tfidf = tfidf_vectorizer.fit_transform(X_as_str).toarray()\n",
    "        embeddings[\"TF-IDF_str\"] = X_tfidf\n",
    "        print(\"TF-IDF (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"TF-IDF embedding error:\", e)\n",
    "\n",
    "    # Count Vectorizer\n",
    "    # Common defaults: max_features=500\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        count_vectorizer = CountVectorizer(max_features=500)\n",
    "        X_count = count_vectorizer.fit_transform(X_as_str).toarray()\n",
    "        embeddings[\"Count_str\"] = X_count\n",
    "        print(\"Count Vectorizer (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"Count Vectorizer embedding error:\", e)\n",
    "\n",
    "    # Character-level TF-IDF\n",
    "    # Common defaults: analyzer='char', ngram_range=(2,4), max_features=500\n",
    "    try:\n",
    "        char_vectorizer = TfidfVectorizer(\n",
    "            analyzer='char',\n",
    "            ngram_range=(2, 4),\n",
    "            max_features=500\n",
    "        )\n",
    "        X_char_tfidf = char_vectorizer.fit_transform(X_as_str).toarray()\n",
    "        embeddings[\"CharTFIDF_str\"] = X_char_tfidf\n",
    "        print(\"Character-level TF-IDF (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"Character-level TF-IDF error:\", e)\n",
    "\n",
    "    # Hashing Vectorizer\n",
    "    # Common defaults: n_features=500\n",
    "    try:\n",
    "        from sklearn.feature_extraction.text import HashingVectorizer\n",
    "        hv = HashingVectorizer(n_features=500)\n",
    "        X_hash = hv.transform(X_as_str).toarray()\n",
    "        embeddings[\"Hashing_str\"] = X_hash\n",
    "        print(\"Hashing Vectorizer (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"Hashing Vectorizer error:\", e)\n",
    "\n",
    "    # SentenceTransformer embedding (requires sentence-transformers)\n",
    "    # Example model: paraphrase-MiniLM-L6-v2 (small & fast)\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        st_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "        X_st = st_model.encode(X_as_str, show_progress_bar=False)\n",
    "        embeddings[\"SentenceTransformer_str\"] = X_st\n",
    "        print(\"SentenceTransformer (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"SentenceTransformer embedding error:\", e)\n",
    "\n",
    "    # DistilBERT embedding via HuggingFace Transformers\n",
    "    # For each row-as-string, tokenize and average the hidden states\n",
    "    try:\n",
    "        from transformers import AutoTokenizer, AutoModel\n",
    "        import torch\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        def get_distilbert_embedding(text):\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            # Mean pooling over token embeddings\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()[0]\n",
    "            return embedding\n",
    "\n",
    "        X_distilbert = np.array([get_distilbert_embedding(txt) for txt in X_as_str])\n",
    "        embeddings[\"DistilBERT_str\"] = X_distilbert\n",
    "        print(\"DistilBERT (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"DistilBERT embedding error:\", e)\n",
    "\n",
    "    # Universal Sentence Encoder (USE) via TensorFlow Hub\n",
    "    # Good universal text embedding, some limitations on max length \n",
    "    try:\n",
    "        import tensorflow_hub as hub\n",
    "        use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "        X_use = use_model(X_as_str).numpy()\n",
    "        embeddings[\"USE_str\"] = X_use\n",
    "        print(\"Universal Sentence Encoder (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"Universal Sentence Encoder embedding error:\", e)\n",
    "\n",
    "    # NMF on the TF-IDF representation (to further reduce dimensionality)\n",
    "    # Common defaults: n_components=2, init='nndsvd'\n",
    "    try:\n",
    "        from sklearn.decomposition import NMF\n",
    "        nmf_model = NMF(n_components=2, init='nndsvd', random_state=42, max_iter=200)\n",
    "        X_nmf = nmf_model.fit_transform(X_tfidf)\n",
    "        embeddings[\"NMF_TFIDF_str\"] = X_nmf\n",
    "        print(\"NMF on TF-IDF (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"NMF embedding error:\", e)\n",
    "\n",
    "    # Doc2Vec embedding using gensim\n",
    "    # vector_size=50, min_count=1, epochs=40 are typical defaults for small data\n",
    "    try:\n",
    "        from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "        documents = [TaggedDocument(words=txt.split(), tags=[str(i)]) for i, txt in enumerate(X_as_str)]\n",
    "        doc2vec_model = Doc2Vec(vector_size=50, min_count=1, epochs=40)\n",
    "        doc2vec_model.build_vocab(documents)\n",
    "        doc2vec_model.train(documents, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "        X_doc2vec = np.array([doc2vec_model.infer_vector(txt.split()) for txt in X_as_str])\n",
    "        embeddings[\"Doc2Vec_str\"] = X_doc2vec\n",
    "        print(\"Doc2Vec (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"Doc2Vec embedding error:\", e)\n",
    "\n",
    "    # Optional: Add Latent Dirichlet Allocation (LDA) for topic modeling on the string data\n",
    "    # This can be done on the TF-IDF or Count vector for text\n",
    "    try:\n",
    "        from sklearn.decomposition import LatentDirichletAllocation\n",
    "        # For demonstration, let's do LDA with 5 topics on the Count vector\n",
    "        if \"Count_str\" in embeddings:\n",
    "            lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "            X_lda = lda_model.fit_transform(embeddings[\"Count_str\"])\n",
    "            embeddings[\"LDA_Count_str\"] = X_lda\n",
    "            print(\"LDA on Count vector (from numeric strings) embedding done.\")\n",
    "    except Exception as e:\n",
    "        print(\"LDA embedding error:\", e)\n",
    "\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://github.com/gagolews/clustering-data-v1/raw/v1.1.0\"\n",
    "\n",
    "def load_data(collection, dataset):\n",
    "    benchmark = clustbench.load_dataset(collection, dataset, url=data_url)\n",
    "    X = benchmark.data\n",
    "    print(\"Loaded: \", X.shape[0], \" | Dimension: \", X.shape[1], \" | Label count: \", len(benchmark.labels))\n",
    "    print(\"Generating Embeddings...\")\n",
    "    return X, benchmark, generate_embeddings(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "each dataset can have multiple labels, \n",
    "pick one at a time and that defines your partition size, aka k\n",
    "\n",
    "Overall, Genie returned a clustering quite similar to the reference one. We may consider 107\n",
    "(namely, c11 + c22 + c33 ) out of the 120 input points as correctly grouped. In particular, \n",
    "all the red and green reference points (the 2nd and the 3rd row) have been properly discovered.\n",
    "\n",
    "Normalized Clustering Accuracy (NCA) \n",
    "NCA is the averaged percentage of correctly classified points in each cluster \n",
    "above the perfectly uniform label distribution.\n",
    "            \n",
    "\"\"\"\n",
    "\n",
    "# Function to calculate Clustering Fidelity (CF)\n",
    "def clustering_fidelity(y_true, y_pred):\n",
    "    # Fidelity could be defined as the percentage of data points correctly assigned to clusters.\n",
    "    return sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "# Function to calculate NCA score (Using AMI as a proxy here)\n",
    "def nca_score(y_true, y_pred):\n",
    "    return adjusted_mutual_info_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def predict(embedding_technique, X, label, benchmark, clustering_method, plot=False):\n",
    "\n",
    "    y_true = benchmark.labels[label] \n",
    "    (k := max(y_true))  # or benchmark.n_clusters[0]\n",
    "    m = max(min(y_true),2)\n",
    "    method = clustering_method.lower()\n",
    "    empty = False\n",
    "\n",
    "    # Define the clustering model\n",
    "    if method == \"genie\":\n",
    "        model = genieclust.Genie(n_clusters=k)  # using default parameters\n",
    "    elif method == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    elif method == \"agglomerative\":\n",
    "        model = AgglomerativeClustering(n_clusters=k)\n",
    "    elif method == \"dbscan\":\n",
    "        model = DBSCAN(eps=0.2, min_samples=m)\n",
    "    elif method == \"meanshift\":\n",
    "        model = MeanShift()\n",
    "    elif method == \"spectral\":\n",
    "        model = SpectralClustering(n_clusters=k, random_state=42)\n",
    "    elif method == \"affinitypropagation\":\n",
    "        model =  AffinityPropagation(random_state=42)\n",
    "    elif method == \"optics\":\n",
    "        model = OPTICS()\n",
    "    elif method == \"gaussianmixture\":\n",
    "        model = GaussianMixture(n_components=k, random_state=42)\n",
    "    elif method == \"hdbscan\":\n",
    "        model = hdbscan.HDBSCAN(min_cluster_size=m)\n",
    "    elif method == \"kmodes\":\n",
    "        model = KModes(n_clusters=k, random_state=42, init=\"Huang\")\n",
    "    elif method == \"birch\":\n",
    "        model = Birch(n_clusters=k)\n",
    "    elif method == \"minibatchkmeans\":\n",
    "        model = MiniBatchKMeans(n_clusters=k, random_state=42)\n",
    "    elif method == \"fcm\":\n",
    "        model = FCM(n_clusters=k)\n",
    "    elif method == \"minisom\":\n",
    "        model = MiniSom(x=10, y=10, input_len=X.shape[1], sigma=1.0, learning_rate=0.5)\n",
    "    elif method == \"kmedoids\":\n",
    "        model = KMedoids(n_clusters=k, random_state=42)\n",
    "    elif method == \"latentdirichletallocation\":\n",
    "        X = np.maximum(X, 0)\n",
    "        model = LatentDirichletAllocation(n_components=k, random_state=42)\n",
    "    elif method == \"spectralcoclustering\":\n",
    "        model =  SpectralCoclustering(n_clusters=k)\n",
    "    elif method == \"bayesiangaussianmixture\":\n",
    "        model = BayesianGaussianMixture(n_components=k)   \n",
    "\n",
    "    print(\"the model: \" +  method + \" has been trained now getting y_pred\") \n",
    "   \n",
    "    # Fit the model and predict the cluster labels\n",
    "    if method == \"gaussianmixture\":  # Gaussian uses predict instead of fit_predict\n",
    "        (y_pred := model.fit(X).predict(X) + 1)\n",
    "    if method == \"fcm\":  # Gaussian uses predict instead of fit_predict\n",
    "        if(model.centers != None):\n",
    "            (y_pred := model.fit(X).predict(X) + 1) \n",
    "        else:\n",
    "            empty = True \n",
    "    elif method == \"minisom\":\n",
    "        model.train(X, 100)\n",
    "        y_pred = np.array([model.winner(x) for x in X]) + 1\n",
    "    elif method == \"latentdirichletallocation\":\n",
    "        model.fit(X)\n",
    "        y_pred = model.transform(X).argmax(axis=1) + 1\n",
    "    elif method == \"spectralcoclustering\":\n",
    "        model.fit(X)\n",
    "        y_pred = y_pred = model.row_labels_ + 1\n",
    "    else:\n",
    "        (y_pred := model.fit_predict(X) + 1)\n",
    "        \n",
    "    # Calculate Clustering Fidelity, NCA (AMI as proxy)\n",
    "    if(empty):\n",
    "        cf = 0\n",
    "        nca = 0\n",
    "    else: \n",
    "        y_true = y_true.flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        if len(y_true) != len(y_pred):\n",
    "            y_pred = y_pred[:len(y_true)]\n",
    "        cf = clustering_fidelity(y_true, y_pred)\n",
    "        nca = nca_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "    if plot and not empty:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        model.plots.plot_scatter(X, labels=y_true-1, axis=\"equal\", title=\"y_true\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        model.plots.plot_scatter(X, labels=y_pred-1, axis=\"equal\", title=\"y_pred\")\n",
    "        plt.show()\n",
    "\n",
    "    return cf, nca_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO unable to figure out the fcm nonetype error and how to handle it would need some help - for now have commented out fcm from the list of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/framework\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd()) # run to check current working directory and update file path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_collections = {\"wut\": [\"x2\"], \"other\": [\"iris\"]}\n",
    "clustering_methods = [\"genie\", \"kmeans\", \"agglomerative\", \"dbscan\", \"meanshift\", \"spectral\", \"affinitypropagation\",\"optics\",\"gaussianmixture\", \"hdbscan\", \"kmodes\", \"birch\", \"minibatchkmeans\", \"minisom\", \"kmedoids\", \"latentdirichletallocation\", \"spectralcoclustering\", \"bayesiangaussianmixture\"]\n",
    "result_csv = \"/Users/ikshitayadav/dev/embedding_based_clustering_research/framework/results/v1_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Run to set the column names for the csv file\n",
    "\"\"\"\n",
    "import os\n",
    "import csv\n",
    "\n",
    "if os.path.exists(result_csv):\n",
    "    print(\"File already exists\")\n",
    "else:\n",
    "    try:\n",
    "        with open(result_csv, mode='w', newline='') as file: \n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Collection\", \"Dataset\", \"Clustering Method\", \"Label\", \"Embedding\", \"NCA Score\"])\n",
    "    except Exception as e:\n",
    "        print(\"Error writing to file: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maybe create a cache or temporary storage for the embeddings\n",
    "# TODO: parallelize the embedding and clustering process per dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: wut, Dataset: x2\n",
      "Loaded:  120  | Dimension:  2  | Label count:  2\n",
      "Generating Embeddings...\n",
      "PCA embedding done.\n",
      "t-SNE embedding done.\n",
      "UMAP embedding done.\n",
      "MDS embedding done.\n",
      "Isomap embedding done.\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "Collection: other, Dataset: iris\n",
      "Loaded:  150  | Dimension:  4  | Label count:  1\n",
      "Generating Embeddings...\n",
      "PCA embedding done.\n",
      "t-SNE embedding done.\n",
      "UMAP embedding done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDS embedding done.\n",
      "Isomap embedding done.\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/manifold/_isomap.py:384: UserWarning: The number of connected components of the neighbors graph is 2 > 1. Completing the graph to fit Isomap might be slow. Increase the number of neighbors to avoid this issue.\n",
      "  self._fit_transform(X)\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/scipy/sparse/_index.py:108: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n",
      "the model: genie has been trained now getting y_pred\n",
      "the model: kmeans has been trained now getting y_pred\n",
      "the model: agglomerative has been trained now getting y_pred\n",
      "the model: dbscan has been trained now getting y_pred\n",
      "the model: meanshift has been trained now getting y_pred\n",
      "the model: spectral has been trained now getting y_pred\n",
      "the model: affinitypropagation has been trained now getting y_pred\n",
      "the model: optics has been trained now getting y_pred\n",
      "the model: gaussianmixture has been trained now getting y_pred\n",
      "the model: hdbscan has been trained now getting y_pred\n",
      "the model: kmodes has been trained now getting y_pred\n",
      "the model: birch has been trained now getting y_pred\n",
      "the model: minibatchkmeans has been trained now getting y_pred\n",
      "the model: minisom has been trained now getting y_pred\n",
      "the model: kmedoids has been trained now getting y_pred\n",
      "the model: latentdirichletallocation has been trained now getting y_pred\n",
      "the model: spectralcoclustering has been trained now getting y_pred\n",
      "the model: bayesiangaussianmixture has been trained now getting y_pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ikshitayadav/dev/embedding_based_clustering_research/myenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(result_csv, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for collection, datasets in eval_collections.items():\n",
    "        for dataset in datasets:\n",
    "            print(f\"Collection: {collection}, Dataset: {dataset}\")\n",
    "            X, benchmark, X_embedded_dict = load_data(collection, dataset)\n",
    "            \n",
    "            for label in range(0, len(benchmark.labels)):\n",
    "                for embedding_technique, embedded_data in X_embedded_dict.items():\n",
    "                    for clustering_method in clustering_methods:\n",
    "                        cf, nca_score = predict(\n",
    "                            embedding_technique, \n",
    "                            embedded_data, \n",
    "                            label, \n",
    "                            benchmark, \n",
    "                            clustering_method\n",
    "                        )\n",
    "                        writer.writerow([\n",
    "                            collection,          # e.g. \"wut\"\n",
    "                            dataset,             # e.g. \"x2\"\n",
    "                            clustering_method,   # e.g. \"genie\"\n",
    "                            label,               # which label set index (0, 1, ...)\n",
    "                            embedding_technique, # e.g. \"PCA\", \"t-SNE\", ...\n",
    "                            cf,                  # confusion matrix\n",
    "                            nca_score            # normalized clustering accuracy\n",
    "                        ])\n",
    "# AR (Adjusted Rand Index): Measures the similarity between two data clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings, adjusted for chance.\n",
    "\n",
    "# R (Rand Index): Similar to AR but not adjusted for chance. It measures the percentage of correct decisions made by the clustering algorithm.\n",
    "\n",
    "# FM (Fowlkes-Mallows Index): Measures the similarity between two clusterings by considering the geometric mean of the precision and recall.\n",
    "\n",
    "# AFM (Adjusted Fowlkes-Mallows Index): An adjusted version of the Fowlkes-Mallows Index that accounts for chance.\n",
    "\n",
    "# MI (Mutual Information): Measures the amount of information obtained about one clustering from the other clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Clustering Method</th>\n",
       "      <th>Label</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>NCA Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>iris</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>Base</td>\n",
       "      <td>{'ar': 0.8857921001989628, 'r': 0.949530201342...</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>iris</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>{'ar': 0.9037675791580496, 'r': 0.957494407158...</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>Base</td>\n",
       "      <td>{'ar': 0.6882872342370341, 'r': 0.859523809523...</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>0</td>\n",
       "      <td>KernelPCA</td>\n",
       "      <td>{'ar': 0.750803955434529, 'r': 0.8880952380952...</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>1</td>\n",
       "      <td>Base</td>\n",
       "      <td>{'ar': 0.6860113896866956, 'r': 0.871988795518...</td>\n",
       "      <td>0.379032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>1</td>\n",
       "      <td>UMAP</td>\n",
       "      <td>{'ar': 0.649943821612011, 'r': 0.8665266106442...</td>\n",
       "      <td>0.548913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>1</td>\n",
       "      <td>Isomap</td>\n",
       "      <td>{'ar': 0.8884037118549749, 'r': 0.955462184873...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>1</td>\n",
       "      <td>LLE</td>\n",
       "      <td>{'ar': 0.6085107451148242, 'r': 0.832352941176...</td>\n",
       "      <td>0.657991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>1</td>\n",
       "      <td>KernelPCA</td>\n",
       "      <td>{'ar': 0.6994166307700244, 'r': 0.878151260504...</td>\n",
       "      <td>0.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>1</td>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>{'ar': 0.799797235568715, 'r': 0.9196078431372...</td>\n",
       "      <td>0.579545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wut</td>\n",
       "      <td>x2</td>\n",
       "      <td>genie</td>\n",
       "      <td>1</td>\n",
       "      <td>RandomProjection</td>\n",
       "      <td>{'ar': 0.7729006525725565, 'r': 0.908683473389...</td>\n",
       "      <td>0.548754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Collection Dataset Clustering Method  Label         Embedding  \\\n",
       "0       other    iris             genie      0              Base   \n",
       "1       other    iris             genie      0       Autoencoder   \n",
       "2         wut      x2             genie      0              Base   \n",
       "3         wut      x2             genie      0         KernelPCA   \n",
       "4         wut      x2             genie      1              Base   \n",
       "5         wut      x2             genie      1              UMAP   \n",
       "6         wut      x2             genie      1            Isomap   \n",
       "7         wut      x2             genie      1               LLE   \n",
       "8         wut      x2             genie      1         KernelPCA   \n",
       "9         wut      x2             genie      1       Autoencoder   \n",
       "10        wut      x2             genie      1  RandomProjection   \n",
       "\n",
       "                                     Confusion Matrix   NCA Score  \n",
       "0   {'ar': 0.8857921001989628, 'r': 0.949530201342...    0.940000  \n",
       "1   {'ar': 0.9037675791580496, 'r': 0.957494407158...    0.950000  \n",
       "2   {'ar': 0.6882872342370341, 'r': 0.859523809523...    0.870000  \n",
       "3   {'ar': 0.750803955434529, 'r': 0.8880952380952...    0.900000  \n",
       "4   {'ar': 0.6860113896866956, 'r': 0.871988795518...    0.379032  \n",
       "5   {'ar': 0.649943821612011, 'r': 0.8665266106442...    0.548913  \n",
       "6   {'ar': 0.8884037118549749, 'r': 0.955462184873...    0.750000  \n",
       "7   {'ar': 0.6085107451148242, 'r': 0.832352941176...    0.657991  \n",
       "8   {'ar': 0.6994166307700244, 'r': 0.878151260504...    0.387097  \n",
       "9   {'ar': 0.799797235568715, 'r': 0.9196078431372...    0.579545  \n",
       "10  {'ar': 0.7729006525725565, 'r': 0.908683473389...    0.548754  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_and_compare_csv(file_path):\n",
    "    # Read the CSV file with the first line as column labels\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Initialize an empty list to store the filtered rows\n",
    "    filtered_rows = []\n",
    "    \n",
    "    # Group the DataFrame by the first four columns\n",
    "    grouped = df.groupby(['Collection', 'Dataset', 'Clustering Method', 'Label'])\n",
    "    \n",
    "    # Iterate over each group\n",
    "    for name, group in grouped:\n",
    "        # Find the \"Base\" row\n",
    "        base_row = group[group['Embedding'] == 'Base']\n",
    "        if not base_row.empty:\n",
    "            base_value = base_row.iloc[0, -1]\n",
    "            base_row_list = base_row.iloc[0].tolist()\n",
    "            base_added = False\n",
    "            \n",
    "            # Iterate over the rows in the group\n",
    "            for index, row in group.iterrows():\n",
    "                if row['Embedding'] != 'Base' and row.iloc[-1] > base_value:\n",
    "                    if not base_added:\n",
    "                        filtered_rows.append(base_row_list)\n",
    "                        base_added = True\n",
    "                    filtered_rows.append(row.tolist())\n",
    "    \n",
    "    # Create a new DataFrame from the filtered rows\n",
    "    filtered_df = pd.DataFrame(filtered_rows, columns=df.columns)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    filtered_df = filtered_df.drop_duplicates()\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Example usage\n",
    "file_path = '/Users/cajoshuapark/Dev/research/embedding_based_clustering_research/framework/results/v1_test.csv'\n",
    "filtered_df = filter_and_compare_csv(file_path)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
