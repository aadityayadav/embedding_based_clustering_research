{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustbench # clustering-benchmarks\n",
    "import os.path, genieclust, sklearn.cluster # we will need these later\n",
    "import matplotlib.pyplot as plt, numpy as np, pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(X):\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    def apply_embedding(model, data):\n",
    "        embedding = model.fit_transform(data)\n",
    "        return embedding\n",
    "\n",
    "    # Example usage with PCA\n",
    "    pca_model = PCA(n_components=2)\n",
    "    X_pca = apply_embedding(pca_model, X)\n",
    "    print(\"PCA Result:\\n\", X_pca[:5])\n",
    "\n",
    "    # Example usage with t-SNE\n",
    "    tsne_model = TSNE(n_components=2, random_state=42)\n",
    "    X_tsne = apply_embedding(tsne_model, X)\n",
    "    print(\"t-SNE Result:\\n\", X_tsne[:5])\n",
    "\n",
    "    X_embedded_dict = {\"Base\": X, \"PCA\": X_pca, \"t-SNE\": X_tsne}\n",
    "    return X_embedded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://github.com/gagolews/clustering-data-v1/raw/v1.1.0\"\n",
    "\n",
    "def load_data(collection, dataset):\n",
    "    benchmark = clustbench.load_dataset(collection, dataset, url=data_url)\n",
    "    X = benchmark.data\n",
    "    print(\"Loaded: \", X.shape[0], \" | Dimension: \", X.shape[1], \" | Label count: \", len(benchmark.labels))\n",
    "    print(\"Generating Embeddings...\")\n",
    "    return X, benchmark, generate_embeddings(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "each dataset can have multiple labels, \n",
    "pick one at a time and that defines your partition size, aka k\n",
    "\"\"\"\n",
    "def predict(embedding_technique, X, label, benchmark, plot=False):\n",
    "    y_true = benchmark.labels[label] \n",
    "    (k := max(y_true))  # or benchmark.n_clusters[0]\n",
    "    # testing genieclust\n",
    "    g = genieclust.Genie(n_clusters=k)  # using default parameters\n",
    "    (y_pred := g.fit_predict(X) + 1)  # +1 makes cluster IDs in 1..k, not 0..(k-1)\n",
    "    \"\"\" \n",
    "    Overall, Genie returned a clustering quite similar to the reference one. We may consider 107\n",
    "    (namely, c11 + c22 + c33 ) out of the 120 input points as correctly grouped. In particular, \n",
    "    all the red and green reference points (the 2nd and the 3rd row) have been properly discovered.\n",
    "    \"\"\"\n",
    "    cf = genieclust.compare_partitions.compare_partitions(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cf)\n",
    "    \"\"\"\n",
    "    Normalized Clustering Accuracy (NCA) \n",
    "    NCA is the averaged percentage of correctly classified points in each cluster \n",
    "    above the perfectly uniform label distribution.\n",
    "    \"\"\"\n",
    "    nca_score = genieclust.compare_partitions.normalized_clustering_accuracy(y_true, y_pred)\n",
    "    print(\"Normalized Clustering Accuracy: \", nca_score)\n",
    "    if plot:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        genieclust.plots.plot_scatter(X, labels=y_true-1, axis=\"equal\", title=\"y_true\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        genieclust.plots.plot_scatter(X, labels=y_pred-1, axis=\"equal\", title=\"y_pred\")\n",
    "        plt.show()\n",
    "    \n",
    "    return cf, nca_score\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaditya/development/embedding_based_clustering_research\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) # run to check current working directory and update file path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nRun to set the column names for the csv file\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Run to set the column names for the csv file\n",
    "\"\"\"\n",
    "# with open('framework/results/v1_test.csv', mode='a', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow([\"Collection\", \"Dataset\", \"Label\", \"Embedding\", \"NCA Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: wut, Dataset: x2\n",
      "Loaded:  120  | Dimension:  2  | Label count:  2\n",
      "Generating Embeddings...\n",
      "PCA Result:\n",
      " [[-0.29902341  0.0486238 ]\n",
      " [-0.47315591  0.20161112]\n",
      " [-0.36135349  0.14382503]\n",
      " [-0.58381059  0.40180117]\n",
      " [-0.50968657 -0.19857204]]\n",
      "t-SNE Result:\n",
      " [[0.9536017  0.11645736]\n",
      " [2.7982829  0.5024181 ]\n",
      " [2.0110471  0.0515926 ]\n",
      " [3.8441398  0.13945578]\n",
      " [0.47838864 2.5857112 ]]\n",
      "Confusion Matrix:\n",
      " {'ar': 0.6882872342370341, 'r': 0.8595238095238096, 'fm': 0.7951855144568276, 'afm': 0.6882935462285218, 'mi': 0.806653849621837, 'nmi': 0.7495519545020478, 'ami': 0.7455077928160847, 'npa': 0.8375000000000001, 'psi': 0.7417149159084644, 'spsi': 0.7384863523573202, 'nca': 0.8700000000000001}\n",
      "Normalized Clustering Accuracy:  0.8700000000000001\n",
      "Confusion Matrix:\n",
      " {'ar': 0.6882872342370341, 'r': 0.8595238095238096, 'fm': 0.7951855144568276, 'afm': 0.6882935462285218, 'mi': 0.806653849621837, 'nmi': 0.7495519545020478, 'ami': 0.7455077928160847, 'npa': 0.8375000000000001, 'psi': 0.7417149159084644, 'spsi': 0.7384863523573202, 'nca': 0.8700000000000001}\n",
      "Normalized Clustering Accuracy:  0.8700000000000001\n",
      "Confusion Matrix:\n",
      " {'ar': 0.6882872342370341, 'r': 0.8595238095238096, 'fm': 0.7951855144568276, 'afm': 0.6882935462285218, 'mi': 0.806653849621837, 'nmi': 0.7495519545020478, 'ami': 0.7455077928160847, 'npa': 0.8375000000000001, 'psi': 0.7417149159084644, 'spsi': 0.7384863523573202, 'nca': 0.8700000000000001}\n",
      "Normalized Clustering Accuracy:  0.8700000000000001\n",
      "Confusion Matrix:\n",
      " {'ar': 0.6860113896866956, 'r': 0.8719887955182073, 'fm': 0.7777535064276708, 'afm': 0.6903861523094433, 'mi': 1.0187221082553575, 'nmi': 0.7523554576331947, 'ami': 0.7417569770964927, 'npa': 0.625, 'psi': 0.2730658898713009, 'spsi': 0.24883475286701096, 'nca': nan}\n",
      "Normalized Clustering Accuracy:  0.3790322580645161\n",
      "Confusion Matrix:\n",
      " {'ar': 0.6860113896866956, 'r': 0.8719887955182073, 'fm': 0.7777535064276708, 'afm': 0.6903861523094433, 'mi': 1.0187221082553575, 'nmi': 0.7523554576331947, 'ami': 0.7417569770964927, 'npa': 0.625, 'psi': 0.2730658898713009, 'spsi': 0.24883475286701096, 'nca': nan}\n",
      "Normalized Clustering Accuracy:  0.3790322580645161\n",
      "Confusion Matrix:\n",
      " {'ar': 0.6860113896866956, 'r': 0.8719887955182073, 'fm': 0.7777535064276708, 'afm': 0.6903861523094433, 'mi': 1.0187221082553575, 'nmi': 0.7523554576331947, 'ami': 0.7417569770964927, 'npa': 0.625, 'psi': 0.2730658898713009, 'spsi': 0.24883475286701096, 'nca': nan}\n",
      "Normalized Clustering Accuracy:  0.3790322580645161\n"
     ]
    }
   ],
   "source": [
    "eval_collections = {\"wut\": [\"x2\"]}\n",
    "\n",
    "with open('framework/results/v1_test.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for collection, datasets in eval_collections.items():\n",
    "        for dataset in datasets:\n",
    "            print(f\"Collection: {collection}, Dataset: {dataset}\")\n",
    "            X, benchmark, X_embedded_dict = load_data(collection, dataset)\n",
    "            for label in range(0, len(benchmark.labels)):\n",
    "                for key, value in X_embedded_dict.items():\n",
    "                    cf, nca_score = predict(key, value, label, benchmark)\n",
    "                    writer.writerow([collection, dataset, label, key, cf, nca_score])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
